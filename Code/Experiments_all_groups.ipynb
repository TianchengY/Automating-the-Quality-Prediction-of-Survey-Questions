{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaee215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_path = 'SQP_dummyvars_data.xlsx'\n",
    "data = pd.read_excel(file_path, sheet_name=None)\n",
    "df = data['Sheet1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the experiment labeling for ESS1 to ESS5\n",
    "def label_experiment(row):\n",
    "    if row['ItemAdmin'] in [\"A1\",\"A3\", \"A5\", \"H1\", \"H2\", \"H3\", \"H19\", \"H20\", \"H21\"] and row['Study'] == \"ESS Round 1\":\n",
    "        return \"ESS1 media_use\"\n",
    "    elif row['ItemAdmin'] in [\"A8\", \"A9\", \"A10\", \"H10\", \"H11\", \"H12\", \"H28\", \"H29\", \"H30\"] and row['Study'] == \"ESS Round 1\":\n",
    "        return \"ESS1 social_trust\"\n",
    "    elif row['ItemAdmin'] in [\"B2\",  \"B3\", \"B4\", \"H4\", \"H5\", \"H6\", \"H22\", \"H23\", \"H24\"] and row['Study'] == \"ESS Round 1\":\n",
    "        return \"ESS1 political_efficacy\"\n",
    "    elif row['ItemAdmin'] in [\"B7\", \"B8\", \"B9\", \"H13\", \"H14\", \"H15\", \"H31\", \"H32\", \"H33\"] and row['Study'] == \"ESS Round 1\":\n",
    "        return \"ESS1 political_trust\"\n",
    "    elif row['ItemAdmin'] in [\"H7\", \"H8\", \"H9\", \"H25\", \"H26\", \"H27\", \"B30\", \"B31\", \"B32\"] and row['Study'] == \"ESS Round 1\":\n",
    "        return \"ESS1 political_satisfaction\"\n",
    "    elif row['ItemAdmin'] in [\"B43\", \"B44\", \"B45\", \"H16\", \"H17\", \"H18\", \"H34\", \"H35\", \"H36\"] and row['Study'] == \"ESS Round 1\":\n",
    "        return \"ESS1 left-right_orientation\"\n",
    "    elif row['ItemAdmin'] in [\"B4\", \"B5\", \"B7\", \"IS25\", \"IS26\", \"IS27\", \"IS38\", \"IS39\", \"IS40\"] and row['Study'] == \"ESS Round 2\":\n",
    "        return \"ESS2 political_trust\"\n",
    "    elif row['ItemAdmin'] in [\"B25\", \"B26\", \"B27\", \"IS11\", \"IS12\", \"IS13\", \"IS35\", \"IS36\", \"IS37\"] and row['Study'] == \"ESS Round 2\":\n",
    "        return \"ESS2 political_satisfaction\"\n",
    "    elif row['ItemAdmin'] in [\"D25\", \"D26\", \"D27\", \"IS5\", \"IS6\", \"IS7\", \"IS28\", \"IS29\", \"IS30\"] and row['Study'] == \"ESS Round 2\":\n",
    "        return \"ESS2 evaluation_of_doctors\"\n",
    "    elif row['ItemAdmin'] in [\"G6\", \"G7\", \"G8\", \"IS8\", \"IS9\", \"IS10\", \"IS22\", \"IS23\", \"IS24\"] and row['Study'] == \"ESS Round 2\":\n",
    "        return \"ESS2 gender_inequalities\"\n",
    "    elif row['ItemAdmin'] in [\"G22\", \"G23\", \"G24\", \"IS2\", \"IS3\", \"IS4\", \"IS15\", \"IS16\", \"IS17\"] and row['Study'] == \"ESS Round 2\":\n",
    "        return \"ESS2 housework\"\n",
    "    elif row['ItemAdmin'] in [\"G64\", \"G66\", \"G70\", \"IS19\", \"IS20\", \"IS21\", \"IS32\", \"IS33\", \"IS34\"] and row['Study'] == \"ESS Round 2\":\n",
    "        return \"ESS2 current_job\"\n",
    "    elif row['ItemAdmin'] in [\"B35\", \"B36\", \"B37\", \"HS1\", \"HS2\", \"HS3\", \"HS13\", \"HS14\", \"HS15\", \"HS25\", \"HS26\", \"HS27\"] and row['Study'] == \"ESS Round 3\":\n",
    "        return \"ESS3 immigration_perceptions\"\n",
    "    elif row['ItemAdmin'] in [\"B38\", \"B39\", \"B40\", \"HS4\", \"HS5\", \"HS6\", \"HS16\", \"HS17\", \"HS18\", \"HS28\", \"HS29\", \"HS30\"] and row['Study'] == \"ESS Round 3\":\n",
    "        return \"ESS3 evaluation_of_immigration\"\n",
    "    elif row['ItemAdmin'] in [\"E26\", \"E27\", \"E28\", \"HS7\", \"HS8\", \"HS9\", \"HS19\", \"HS20\", \"HS21\", \"HS31\", \"HS32\", \"HS33\"] and row['Study'] == \"ESS Round 3\":\n",
    "        return \"ESS3 eudaimonic_well-being\"\n",
    "    elif row['ItemAdmin'] in [\"E40\", \"E43\", \"E45\", \"HS10\", \"HS11\", \"HS12\", \"HS22\", \"HS23\", \"HS24\", \"HS34\", \"HS35\", \"HS36\"] and row['Study'] == \"ESS Round 3\":\n",
    "        return \"ESS3 life_satisfaction\"\n",
    "    elif row['ItemAdmin'] in [\"A1\", \"A3\", \"A5\", \"HS1\", \"HS2\", \"HS3\", \"HS13\", \"HS14\", \"HS15\"] and row['Study'] == \"ESS Round 4\":\n",
    "        return \"ESS4 media_use\"\n",
    "    elif row['ItemAdmin'] in [\"A8\", \"A9\", \"HS4\", \"HS5\", \"HS6\", \"HS25\", \"HS26\", \"HS27\"] and row['Study'] == \"ESS Round 4\":\n",
    "        return \"ESS4 social_trust\"\n",
    "    elif row['ItemAdmin'] in [\"B4\", \"B5\", \"B6\", \"HS16\", \"HS17\", \"HS18\", \"HS28\", \"HS29\", \"HS30\"] and row['Study'] == \"ESS Round 4\":\n",
    "        return \"ESS4 political_trust\"\n",
    "    elif row['ItemAdmin'] in [\"B23\", \"HS22\", \"HS23\", \"HS24\", \"HS34\", \"HS35\", \"HS36\"] and row['Study'] == \"ESS Round 4\":\n",
    "        return \"ESS4 left-right_placement\"\n",
    "    elif row['ItemAdmin'] in [\"B25\", \"B26\", \"B27\", \"HS7\", \"HS8\", \"HS9\", \"HS19\", \"HS20\", \"HS21\"] and row['Study'] == \"ESS Round 4\":\n",
    "        return \"ESS4 political_satisfaction\"\n",
    "    elif row['ItemAdmin'] in [\"B30\", \"B31\", \"HS10\", \"HS11\", \"HS12\", \"HS31\", \"HS32\", \"HS33\"] and row['Study'] == \"ESS Round 4\":\n",
    "        return \"ESS4 left-right_orientation\"\n",
    "    elif row['ItemAdmin'] in [\"D4\", \"D5\", \"D6\", \"I10\", \"I11\", \"I12\", \"I19\", \"I20\", \"I21\"] and row['Study'] == \"ESS Round 5\":\n",
    "        return \"ESS5 effectiveness_of_the_police\"\n",
    "    elif row['ItemAdmin'] in [\"D12\", \"D13\", \"D14\", \"I15\", \"I13\", \"I14\", \"I4\", \"I5\", \"I6\"] and row['Study'] == \"ESS Round 5\":\n",
    "        return \"ESS5 satisfaction_with_the_police\"\n",
    "    elif row['ItemAdmin'] in [\"D15\", \"D17\", \"D16\", \"I7\", \"I8\", \"I9\", \"I16\", \"I17\", \"I18\"] and row['Study'] == \"ESS Round 5\":\n",
    "        return \"ESS5 evaluation_of_the_police\"\n",
    "    # ESS Round 6\n",
    "    elif row['ItemName'] in [\"imbgeco\", \"imueclt\", \"imwbcnt\", \"teste19\", \"teste20\", \"teste21\", \"teste28\", \"teste29\", \"teste30\"] and row['Study'] == \"ESS Round 6\":\n",
    "        return \"ESS6 evaluation_of_immigration\"\n",
    "    elif row['ItemName'] in [\"fltdpr\", \"slprl\", \"fltlnl\", \"teste4\", \"teste5\", \"teste6\", \"teste13\", \"teste14\", \"teste15\", \"teste25\", \"teste26\", \"teste27\", \"teste34\", \"teste35\", \"teste36\"] and row['Study'] == \"ESS Round 6\":\n",
    "        return \"ESS6 feelings_past_week\"\n",
    "    elif row['ItemName'] in [\"tmimdng\", \"tmabdng\", \"tmendng\", \"teste1\", \"teste2\", \"teste3\", \"teste10\", \"teste11\", \"teste12\", \"teste22\", \"teste23\", \"teste24\", \"teste31\", \"teste32\", \"teste33\"] and row['Study'] == \"ESS Round 6\":\n",
    "        return \"ESS6 everyday_life_engagement\"\n",
    "    elif row['ItemName'] in [\"oppcrgvc\",\"medcrgvc\",\"meprinfc\",\"teste7\", \"teste8\", \"teste9\", \"teste16\", \"teste17\", \"teste18\"] and row['Study'] == \"ESS Round 6\":\n",
    "        return \"ESS6 evaluation_of_democracy\"\n",
    "    # ESS Round 7\n",
    "    elif row['ItemName'] in [\"psppsgv\", \"psppipl\", \"ptcpplt\", \"testf4\", \"testf5\", \"testf6\", \"testf13\", \"testf14\", \"testf15\"] and row['Study'] == \"ESS Round 7\":\n",
    "        return \"ESS7 system_responsiveness\"\n",
    "    elif row['ItemName'] in [\"actrolg\", \"cptppol\", \"etapapl\", \"testf7\", \"testf8\", \"testf9\", \"testf16\", \"testf17\", \"testf18\"] and row['Study'] == \"ESS Round 7\":\n",
    "        return \"ESS7 subjective_competence\"\n",
    "    elif row['ItemName'] in [\"qfimlng\", \"qfimwht\", \"qfimcmt\", \"testf1\", \"testf2\", \"testf3\", \"testf10\", \"testf11\", \"testf12\"] and row['Study'] == \"ESS Round 7\":\n",
    "        return \"ESS7 importance_to_immigration\"\n",
    "    return None\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "df['experiment'] = df.apply(label_experiment, axis=1)\n",
    "\n",
    "# Filter for rows where 'experiment' is not None\n",
    "data_csv = df[df['experiment'].notnull()]\n",
    "data_excel = df[df['experiment'].isnull()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dcb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Function to preprocess the text based on 'Introduction text' length\n",
    "def preprocess_text(row):\n",
    "    if len(str(row['Introduction text'])) > 10:\n",
    "        return row['Introduction text'] + \" \" + row['Request for answer text']\n",
    "    else:\n",
    "        return \"</no introduction text/> \" + row['Request for answer text']\n",
    "\n",
    "\n",
    "# Apply preprocessing to the CSV data\n",
    "data_csv['Processed Request for answer text'] = data_csv.apply(preprocess_text, axis=1)\n",
    "\n",
    "# Apply preprocessing to the Excel data\n",
    "data_excel['Processed Request for answer text'] = data_excel.apply(preprocess_text, axis=1)\n",
    "\n",
    "# Separate out ESS1 political_efficacy as the final validation set from CSV data\n",
    "validation_data_csv = data_csv[data_csv['experiment'] == 'ESS1 political_efficacy']\n",
    "data_csv = data_csv[data_csv['experiment'] != 'ESS1 political_efficacy']  # Remaining data for train/test split\n",
    "\n",
    "# Ensure no missing values in the 'quality(q^2)' column\n",
    "data_csv = data_csv.dropna(subset=[\"quality(q^2)\"])\n",
    "data_excel = data_excel.dropna(subset=[\"quality(q^2)\"])\n",
    "\n",
    "# Split CSV data based on unique 'experiment' groups for training and testing\n",
    "unique_experiments = data_csv['experiment'].unique()\n",
    "train_experiments_csv, test_experiments_csv = train_test_split(unique_experiments, test_size=0.2, random_state=42)\n",
    "train_data_csv = data_csv[data_csv['experiment'].isin(train_experiments_csv)]\n",
    "test_data_csv = data_csv[data_csv['experiment'].isin(test_experiments_csv)]\n",
    "\n",
    "# Split Excel data based on unique 'study' groups for training and testing\n",
    "unique_studies = data_excel['Study'].unique()\n",
    "train_studies_excel, test_studies_excel = train_test_split(unique_studies, test_size=0.2, random_state=42)\n",
    "train_data_excel = data_excel[data_excel['Study'].isin(train_studies_excel)]\n",
    "test_data_excel = data_excel[data_excel['Study'].isin(test_studies_excel)]\n",
    "\n",
    "# Extract features and labels for CSV data\n",
    "train_features_csv = train_data_csv[[\"Processed Request for answer text\", \"Answer options text\"]]\n",
    "train_labels_csv = train_data_csv[\"quality(q^2)\"]\n",
    "test_features_csv = test_data_csv[[\"Processed Request for answer text\", \"Answer options text\"]]\n",
    "test_labels_csv = test_data_csv[\"quality(q^2)\"]\n",
    "\n",
    "# Extract features and labels for Excel data\n",
    "train_features_excel = train_data_excel[[\"Processed Request for answer text\", \"Answer options text\"]]\n",
    "train_labels_excel = train_data_excel[\"quality(q^2)\"]\n",
    "test_features_excel = test_data_excel[[\"Processed Request for answer text\", \"Answer options text\"]]\n",
    "test_labels_excel = test_data_excel[\"quality(q^2)\"]\n",
    "\n",
    "# Combine the training data from both sources\n",
    "train_features_combined = pd.concat([train_features_csv, train_features_excel], ignore_index=True)\n",
    "train_labels_combined = pd.concat([train_labels_csv, train_labels_excel], ignore_index=True)\n",
    "\n",
    "# Combine the testing data from both sources\n",
    "test_features_combined = pd.concat([test_features_csv, test_features_excel], ignore_index=True)\n",
    "test_labels_combined = pd.concat([test_labels_csv, test_labels_excel], ignore_index=True)\n",
    "\n",
    "# Prepare the validation set features and labels\n",
    "validation_features_csv = validation_data_csv[[\"Processed Request for answer text\", \"Answer options text\"]]\n",
    "validation_labels_csv = validation_data_csv[\"quality(q^2)\"]\n",
    "\n",
    "# Define a dataset class\n",
    "class QualityDataset(Dataset):\n",
    "    def __init__(self, tokenizer, texts, labels=None):\n",
    "        self.encodings = tokenizer(texts[0], texts[1], truncation=True, padding=True, max_length=128)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "# Prepare the combined datasets\n",
    "train_dataset = QualityDataset(tokenizer, (\n",
    "    train_features_combined[\"Processed Request for answer text\"].tolist(), \n",
    "    train_features_combined[\"Answer options text\"].tolist()), train_labels_combined.tolist())\n",
    "\n",
    "test_dataset = QualityDataset(tokenizer, (\n",
    "    test_features_combined[\"Processed Request for answer text\"].tolist(), \n",
    "    test_features_combined[\"Answer options text\"].tolist()), test_labels_combined.tolist())\n",
    "\n",
    "validation_dataset = QualityDataset(tokenizer, (\n",
    "    validation_features_csv[\"Processed Request for answer text\"].tolist(), \n",
    "    validation_features_csv[\"Answer options text\"].tolist()), validation_labels_csv.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89bcfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    lr_scheduler_type='cosine',\n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "# Define MSE computation for evaluation\n",
    "def compute_mse(p):\n",
    "    return {\"mse\": mean_squared_error(p.label_ids, p.predictions.squeeze())}\n",
    "\n",
    "# Load the model\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=1)\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_mse,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3614a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01368d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from CSV\n",
    "data_csv = pd.read_csv(\"final_exp_group_eng_manual.csv\")\n",
    "\n",
    "# Load the data from Excel\n",
    "data_excel = pd.read_csv(\"final_exp_nongroup_eng.csv\")\n",
    "\n",
    "# Apply preprocessing to the CSV data\n",
    "data_csv['Processed Request for answer text'] = data_csv.apply(preprocess_text, axis=1)\n",
    "\n",
    "# Apply preprocessing to the Excel data\n",
    "data_excel['Processed Request for answer text'] = data_excel.apply(preprocess_text, axis=1)\n",
    "\n",
    "# Separate out ESS1 political_efficacy as the final validation set from CSV data\n",
    "validation_data_csv = data_csv[data_csv['experiment'] == 'ESS1 political_efficacy']\n",
    "# Prepare the validation set features and labels\n",
    "validation_features_csv = validation_data_csv[[\"Processed Request for answer text\", \"Answer options text\"]]\n",
    "validation_labels_csv = validation_data_csv[\"quality(q^2)\"]\n",
    "validation_dataset = QualityDataset(tokenizer, (\n",
    "    validation_features_csv[\"Processed Request for answer text\"].tolist(), \n",
    "    validation_features_csv[\"Answer options text\"].tolist()), validation_labels_csv.tolist())\n",
    "\n",
    "\n",
    "# Use trainer to predict on the test data CSV\n",
    "predictions = trainer.predict(validation_dataset)\n",
    "\n",
    "# Extract the predicted labels\n",
    "predicted_labels = predictions.predictions.squeeze()\n",
    "\n",
    "# Compare predicted labels with actual labels\n",
    "mse = mean_squared_error(validation_labels_csv, predicted_labels)\n",
    "print(f\"Mean Squared Error on the test set: {mse}\")\n",
    "\n",
    "# Optionally, save predictions to a CSV file\n",
    "output_df = validation_features_csv.copy()\n",
    "output_df['actual_quality'] = validation_labels_csv\n",
    "output_df['predicted_quality'] = predicted_labels\n",
    "output_df.to_csv('./group_results_allrandom/predictionsESS1 political_efficacy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d4b59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
